{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "131e0496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace91bfe",
   "metadata": {},
   "source": [
    "# Bueno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9df68e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 21:39:28,794 [INFO] üîÑ Cargando y limpiando datos...\n",
      "2025-04-09 21:39:28,821 [INFO] üöÄ Consultando Wikidata...\n",
      "üîé Batches SPARQL:   0%|          | 60/29858 [00:14<1:57:06,  4.24it/s]2025-04-09 21:39:43,211 [ERROR] ‚ùå Error intento 1: 400 Client Error: Bad Request for url: https://query.wikidata.org/sparql ‚Üí Reintentando en 1.0s...\n",
      "2025-04-09 21:39:44,480 [ERROR] ‚ùå Error intento 2: 400 Client Error: Bad Request for url: https://query.wikidata.org/sparql ‚Üí Reintentando en 2.2s...\n",
      "2025-04-09 21:39:46,926 [ERROR] ‚ùå Error intento 3: 400 Client Error: Bad Request for url: https://query.wikidata.org/sparql ‚Üí Reintentando en 4.5s...\n",
      "2025-04-09 21:39:51,778 [ERROR] ‚ùå Error intento 4: 400 Client Error: Bad Request for url: https://query.wikidata.org/sparql ‚Üí Reintentando en 8.4s...\n",
      "üîé Batches SPARQL:   0%|          | 60/29858 [00:31<4:19:12,  1.92it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 79\u001b[39m, in \u001b[36mobtener_datos_wikidata\u001b[39m\u001b[34m(artistas_batch, max_retries)\u001b[39m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel Burgos\\OneDrive\\Documentos\\GitHub\\Workshop_2\\venv\\Lib\\site-packages\\requests\\models.py:1024\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 400 Client Error: Bad Request for url: https://query.wikidata.org/sparql",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 110\u001b[39m\n\u001b[32m    107\u001b[39m     batch_size -= \u001b[32m5\u001b[39m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m data = \u001b[43mobtener_datos_wikidata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data[\u001b[33m\"\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mbindings\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 84\u001b[39m, in \u001b[36mobtener_datos_wikidata\u001b[39m\u001b[34m(artistas_batch, max_retries)\u001b[39m\n\u001b[32m     82\u001b[39m         wait = \u001b[32m2\u001b[39m ** intento + random.uniform(\u001b[32m0\u001b[39m, \u001b[32m0.5\u001b[39m)\n\u001b[32m     83\u001b[39m         logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚ùå Error intento \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mintento\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ‚Üí Reintentando en \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwait\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m logger.critical(\u001b[33m\"\u001b[39m\u001b[33müö´ Fallo final tras m√∫ltiples reintentos.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "import html\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===========================\n",
    "# 1. CONFIGURACI√ìN DEL LOGGER\n",
    "# ===========================\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),\n",
    "        # logging.FileHandler(\"wikidata_etl.log\")  # Descomenta si quieres guardar en archivo\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# =======================\n",
    "# 2. CARGAR Y LIMPIAR CSV\n",
    "# =======================\n",
    "logger.info(\"üîÑ Cargando y limpiando datos...\")\n",
    "\n",
    "df = pd.read_csv(\"../data/artists.csv\", header=None, names=[\"raw\"])\n",
    "artistas_unicos = df['raw'].dropna().unique()\n",
    "\n",
    "# =======================\n",
    "# 3. FUNCIONES DE APOYO\n",
    "# =======================\n",
    "def limpiar_nombre(nombre):\n",
    "    nombre = str(nombre)\n",
    "    nombre = nombre.replace('\"', '\\\\\"')\n",
    "    nombre = nombre.replace(\"\\n\", \" \").strip()\n",
    "    return html.escape(nombre)\n",
    "\n",
    "def construir_query_sparql(artistas):\n",
    "    values = \"\\n\".join([f'\"{limpiar_nombre(nombre)}\"@en' for nombre in artistas])\n",
    "    query = f\"\"\"\n",
    "    SELECT ?artistLabel ?death ?countryLabel ?awardLabel ?genderLabel WHERE {{\n",
    "      VALUES ?name {{ {values} }}\n",
    "      ?artist rdfs:label ?name.\n",
    "      ?artist wdt:P166 ?award.\n",
    "      ?award rdfs:label ?awardLabel.\n",
    "      OPTIONAL {{ ?artist wdt:P27 ?country. }}\n",
    "      OPTIONAL {{ ?artist wdt:P570 ?death. }}\n",
    "      OPTIONAL {{ ?artist wdt:P21 ?gender. }}\n",
    "      SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return query\n",
    "\n",
    "# =======================\n",
    "# 4. CONSULTA ROBUSTA\n",
    "# =======================\n",
    "WIKIDATA_ENDPOINT = \"https://query.wikidata.org/sparql\"\n",
    "HEADERS = {\n",
    "    \"Accept\": \"application/sparql-results+json\",\n",
    "    \"User-Agent\": \"ETL-Musical-Artists/1.0 (tucorreo@ejemplo.com)\"\n",
    "}\n",
    "\n",
    "def obtener_datos_wikidata(artistas_batch, max_retries=4):\n",
    "    query = construir_query_sparql(artistas_batch)\n",
    "    for intento in range(max_retries):\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                WIKIDATA_ENDPOINT,\n",
    "                headers=HEADERS,\n",
    "                data={\"query\": query},\n",
    "                timeout=30\n",
    "            )\n",
    "            if response.status_code == 429:\n",
    "                wait = 2 ** intento + random.uniform(0, 0.5)\n",
    "                logger.warning(f\"‚ö†Ô∏è  429 Too Many Requests. Esperando {wait:.1f}s...\")\n",
    "                time.sleep(wait)\n",
    "                continue\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            wait = 2 ** intento + random.uniform(0, 0.5)\n",
    "            logger.error(f\"‚ùå Error intento {intento + 1}: {e} ‚Üí Reintentando en {wait:.1f}s...\")\n",
    "            time.sleep(wait)\n",
    "    logger.critical(\"üö´ Fallo final tras m√∫ltiples reintentos.\")\n",
    "    return None\n",
    "\n",
    "# =======================\n",
    "# 5. CONSULTA POR BATCHES\n",
    "# =======================\n",
    "logger.info(\"üöÄ Consultando Wikidata...\")\n",
    "\n",
    "MAX_QUERY_SIZE = 60000\n",
    "results = []\n",
    "i = 0\n",
    "\n",
    "with tqdm(total=len(artistas_unicos), desc=\"üîé Batches SPARQL\") as pbar:\n",
    "    while i < len(artistas_unicos):\n",
    "        batch_size = 60\n",
    "        batch_success = False\n",
    "\n",
    "        while batch_size > 0 and not batch_success:\n",
    "            batch = artistas_unicos[i:i+batch_size]\n",
    "            query = construir_query_sparql(batch)\n",
    "\n",
    "            if len(query.encode(\"utf-8\")) > MAX_QUERY_SIZE:\n",
    "                batch_size -= 5\n",
    "                continue\n",
    "\n",
    "            data = obtener_datos_wikidata(batch)\n",
    "            if data:\n",
    "                for row in data[\"results\"][\"bindings\"]:\n",
    "                    results.append({\n",
    "                        \"artist\": row.get(\"artistLabel\", {}).get(\"value\", \"\"),\n",
    "                        \"death\": row.get(\"death\", {}).get(\"value\", \"\"),\n",
    "                        \"country\": row.get(\"countryLabel\", {}).get(\"value\", \"\"),\n",
    "                        \"award\": row.get(\"awardLabel\", {}).get(\"value\", \"No awards\"),\n",
    "                        \"gender\": row.get(\"genderLabel\", {}).get(\"value\", \"Unknown\")\n",
    "                    })\n",
    "                logger.debug(f\"‚úÖ Batch exitoso en √≠ndice {i} (size={batch_size})\")\n",
    "                i += batch_size\n",
    "                pbar.update(batch_size)\n",
    "                batch_success = True\n",
    "            else:\n",
    "                batch_size = batch_size // 2\n",
    "\n",
    "        if not batch_success:\n",
    "            logger.warning(f\"‚ö†Ô∏è  Saltando artista en √≠ndice {i}: {artistas_unicos[i]}\")\n",
    "            i += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "# =======================\n",
    "# 6. GUARDAR RESULTADOS\n",
    "# =======================\n",
    "columnas_ordenadas = [\"artist\", \"country\", \"award\", \"death\", \"gender\"]\n",
    "df_result = pd.DataFrame(results, columns=columnas_ordenadas)\n",
    "#df_result.to_csv(\"../data/api_data.csv\", index=False)\n",
    "logger.info(\"‚úÖ Datos guardados en '../data/api_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdafbdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Cargando y limpiando datos...\n",
      "üöÄ Consultando Wikidata...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Batches SPARQL:   0%|          | 60/29859 [00:01<10:28, 47.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error en SPARQL: 400 Client Error: Bad Request for url: https://query.wikidata.org/sparql\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Batches SPARQL:   0%|          | 90/29859 [00:06<43:39, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error en SPARQL: 400 Client Error: Bad Request for url: https://query.wikidata.org/sparql\n",
      "‚ùå Error en SPARQL: 400 Client Error: Bad Request for url: https://query.wikidata.org/sparql\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Batches SPARQL:   0%|          | 105/29859 [00:09<51:50,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error en SPARQL: 400 Client Error: Bad Request for url: https://query.wikidata.org/sparql\n",
      "‚ùå Error en SPARQL: 400 Client Error: Bad Request for url: https://query.wikidata.org/sparql\n",
      "‚ùå Error en SPARQL: 400 Client Error: Bad Request for url: https://query.wikidata.org/sparql\n",
      "‚ùå Error en SPARQL: 400 Client Error: Bad Request for url: https://query.wikidata.org/sparql\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Batches SPARQL:   0%|          | 108/29859 [00:11<1:12:10,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error en SPARQL: 400 Client Error: Bad Request for url: https://query.wikidata.org/sparql\n",
      "‚ùå Error en SPARQL: 400 Client Error: Bad Request for url: https://query.wikidata.org/sparql\n",
      "‚ùå Error en SPARQL: 400 Client Error: Bad Request for url: https://query.wikidata.org/sparql\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Batches SPARQL:   0%|          | 108/29859 [00:13<1:02:42,  7.91it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     59\u001b[39m     batch_size -= \u001b[32m5\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m data = \u001b[43mobtener_datos_wikidata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data[\u001b[33m\"\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mbindings\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mobtener_datos_wikidata\u001b[39m\u001b[34m(artistas_batch)\u001b[39m\n\u001b[32m     32\u001b[39m headers = {\u001b[33m\"\u001b[39m\u001b[33mAccept\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mapplication/sparql-results+json\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWIKIDATA_ENDPOINT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m     response.raise_for_status()\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel Burgos\\OneDrive\\Documentos\\GitHub\\Workshop_2\\venv\\Lib\\site-packages\\requests\\api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel Burgos\\OneDrive\\Documentos\\GitHub\\Workshop_2\\venv\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel Burgos\\OneDrive\\Documentos\\GitHub\\Workshop_2\\venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel Burgos\\OneDrive\\Documentos\\GitHub\\Workshop_2\\venv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel Burgos\\OneDrive\\Documentos\\GitHub\\Workshop_2\\venv\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel Burgos\\OneDrive\\Documentos\\GitHub\\Workshop_2\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel Burgos\\OneDrive\\Documentos\\GitHub\\Workshop_2\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Michel Burgos\\OneDrive\\Documentos\\GitHub\\Workshop_2\\venv\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:1378\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1376\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1377\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1378\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1379\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1380\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:318\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    320\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:279\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fp.readline(_MAXLINE + \u001b[32m1\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    280\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    281\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:706\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    705\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    708\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1278\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1275\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1276\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1277\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1278\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1279\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1280\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1134\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1132\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1133\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1134\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1135\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1136\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# =======================\n",
    "# 1. CARGAR Y LIMPIAR CSV\n",
    "# =======================\n",
    "print(\"üîÑ Cargando y limpiando datos...\")\n",
    "\n",
    "df = pd.read_csv(\"../data/artists.csv\", header=None, names=[\"raw\"])\n",
    "artistas_unicos = df['raw'].unique()\n",
    "\n",
    "# =======================\n",
    "# 2. CONSULTA SPARQL CON TODOS LOS CAMPOS\n",
    "# =======================\n",
    "WIKIDATA_ENDPOINT = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "def construir_query_sparql(artistas):\n",
    "    values = \"\\n\".join([f'\"{nombre}\"@en' for nombre in artistas])\n",
    "    query = f\"\"\"\n",
    "    SELECT ?artistLabel ?death ?countryLabel ?awardLabel ?genderLabel WHERE {{\n",
    "      VALUES ?name {{ {values} }}\n",
    "      ?artist rdfs:label ?name.\n",
    "      ?artist wdt:P166 ?award.\n",
    "      ?award rdfs:label ?awardLabel.\n",
    "      OPTIONAL {{ ?artist wdt:P27 ?country. }}\n",
    "      OPTIONAL {{ ?artist wdt:P570 ?death. }}\n",
    "      OPTIONAL {{ ?artist wdt:P21 ?gender. }}  # G√©nero con P21\n",
    "      SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return query\n",
    "\n",
    "def obtener_datos_wikidata(artistas_batch):\n",
    "    query = construir_query_sparql(artistas_batch)\n",
    "    headers = {\"Accept\": \"application/sparql-results+json\"}\n",
    "    try:\n",
    "        response = requests.post(WIKIDATA_ENDPOINT, data={\"query\": query}, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"‚ùå Error en SPARQL:\", e)\n",
    "        return None\n",
    "\n",
    "# =======================\n",
    "# 3. CONSULTA ROBUSTA\n",
    "# =======================\n",
    "print(\"üöÄ Consultando Wikidata...\")\n",
    "\n",
    "MAX_QUERY_SIZE = 60000\n",
    "results = []\n",
    "i = 0\n",
    "\n",
    "with tqdm(total=len(artistas_unicos), desc=\"üîé Batches SPARQL\") as pbar:\n",
    "    while i < len(artistas_unicos):\n",
    "        batch_size = 60\n",
    "        batch_success = False\n",
    "\n",
    "        while batch_size > 0 and not batch_success:\n",
    "            batch = artistas_unicos[i:i+batch_size]\n",
    "            query = construir_query_sparql(batch)\n",
    "            if len(query.encode(\"utf-8\")) > MAX_QUERY_SIZE:\n",
    "                batch_size -= 5\n",
    "                continue\n",
    "\n",
    "            data = obtener_datos_wikidata(batch)\n",
    "            if data:\n",
    "                for row in data[\"results\"][\"bindings\"]:\n",
    "                    results.append({\n",
    "                        \"artist\": row.get(\"artistLabel\", {}).get(\"value\", \"\"),\n",
    "                        \"death\": row.get(\"death\", {}).get(\"value\", \"\"),\n",
    "                        \"country\": row.get(\"countryLabel\", {}).get(\"value\", \"\"),\n",
    "                        \"award\": row.get(\"awardLabel\", {}).get(\"value\", \"No awards\"),\n",
    "                        \"gender\": row.get(\"genderLabel\", {}).get(\"value\", \"Unknown\")  # Valor por defecto si no hay g√©nero\n",
    "                    })\n",
    "                batch_success = True\n",
    "                i += batch_size\n",
    "                pbar.update(batch_size)\n",
    "                time.sleep(1)\n",
    "            else:\n",
    "                batch_size = batch_size // 2\n",
    "\n",
    "        if not batch_success:\n",
    "            print(f\"‚ö†Ô∏è  Saltando artista en √≠ndice {i}: {artistas_unicos[i]}\")\n",
    "            i += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "# =======================\n",
    "# 4. GUARDAR RESULTADOS\n",
    "# =======================\n",
    "columnas_ordenadas = [\"artist\", \"country\", \"award\", \"death\", \"gender\"]\n",
    "df_result = pd.DataFrame(results, columns=columnas_ordenadas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc75855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Total artistas √∫nicos: 29856\n",
      "üöÄ Consultando Wikidata...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Batches SPARQL: 29920it [14:01, 35.56it/s]                           \n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# 1. CARGAR Y LIMPIAR CSV\n",
    "# =======================\n",
    "# Funci√≥n para limpiar nombres\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def limpiar_nombre(nombre):\n",
    "    if pd.isna(nombre) or not nombre.strip():\n",
    "        return None\n",
    "    # Eliminar caracteres problem√°ticos para SPARQL\n",
    "    nombre = nombre.replace(\"\\\\\", \"\")   # Quitar backslashes\n",
    "    nombre = nombre.replace('\"', '')    # Quitar comillas dobles\n",
    "    nombre = nombre.replace(\"'\", \"\")    # Quitar comillas simples\n",
    "    nombre = nombre.replace(\"/\", \" \")   # Evitar errores con `/`\n",
    "    nombre = nombre.replace(\"&\", \"and\") # Evitar ambig√ºedad\n",
    "    nombre = nombre.strip()\n",
    "    return nombre\n",
    "\n",
    "# Cargar y limpiar\n",
    "df = pd.read_csv(\"../data/artists.csv\", header=None, names=[\"raw\"])\n",
    "nombres_limpios = [limpiar_nombre(nombre) for nombre in df[\"raw\"]]\n",
    "artistas_unicos = sorted(set([nombre for nombre in nombres_limpios if nombre]))\n",
    "\n",
    "print(f\"‚úÖ Total artistas √∫nicos: {len(artistas_unicos)}\")\n",
    "\n",
    "\n",
    "# =======================\n",
    "# 2. CONSULTA SPARQL CON TODOS LOS CAMPOS\n",
    "# =======================\n",
    "WIKIDATA_ENDPOINT = \"https://query.wikidata.org/sparql\"\n",
    "HEADERS = {\n",
    "    \"Accept\": \"application/sparql-results+json\",\n",
    "    \"User-Agent\": \"ETL-MusicalProject/1.0 (malvadocucarachon@gmail.com)\"  # <-- ¬°Pon tu info real aqu√≠!\n",
    "}\n",
    "\n",
    "\n",
    "def construir_query_sparql(artistas):\n",
    "    values = \"\\n\".join([f'\"{nombre}\"@en' for nombre in artistas])\n",
    "    query = f\"\"\"\n",
    "    SELECT ?artistLabel ?death ?countryLabel ?awardLabel ?genderLabel WHERE {{\n",
    "      VALUES ?name {{ {values} }}\n",
    "      ?artist rdfs:label ?name.\n",
    "      ?artist wdt:P166 ?award.\n",
    "      ?award rdfs:label ?awardLabel.\n",
    "      OPTIONAL {{ ?artist wdt:P27 ?country. }}\n",
    "      OPTIONAL {{ ?artist wdt:P570 ?death. }}\n",
    "      OPTIONAL {{ ?artist wdt:P21 ?gender. }}  # G√©nero con P21\n",
    "      SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return query\n",
    "\n",
    "def obtener_datos_wikidata(artistas_batch):\n",
    "    query = construir_query_sparql(artistas_batch)\n",
    "    try:\n",
    "        response = requests.post(WIKIDATA_ENDPOINT, data={\"query\": query}, headers=HEADERS)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"‚ùå Error en SPARQL:\", e)\n",
    "        return None\n",
    "\n",
    "# =======================\n",
    "# 3. CONSULTA ROBUSTA\n",
    "# =======================\n",
    "print(\"üöÄ Consultando Wikidata...\")\n",
    "\n",
    "MAX_QUERY_SIZE = 60000\n",
    "results = []\n",
    "i = 0\n",
    "\n",
    "with tqdm(total=len(artistas_unicos), desc=\"üîé Batches SPARQL\") as pbar:\n",
    "    while i < len(artistas_unicos):\n",
    "        batch_size = 80\n",
    "        batch_success = False\n",
    "\n",
    "        while batch_size > 0 and not batch_success:\n",
    "            batch = artistas_unicos[i:i+batch_size]\n",
    "            query = construir_query_sparql(batch)\n",
    "            if len(query.encode(\"utf-8\")) > MAX_QUERY_SIZE:\n",
    "                batch_size -= 5\n",
    "                continue\n",
    "\n",
    "            data = obtener_datos_wikidata(batch)\n",
    "            if data:\n",
    "                for row in data[\"results\"][\"bindings\"]:\n",
    "                    results.append({\n",
    "                        \"artist\": row.get(\"artistLabel\", {}).get(\"value\", \"\"),\n",
    "                        \"death\": row.get(\"death\", {}).get(\"value\", \"\"),\n",
    "                        \"country\": row.get(\"countryLabel\", {}).get(\"value\", \"\"),\n",
    "                        \"award\": row.get(\"awardLabel\", {}).get(\"value\", \"No awards\"),\n",
    "                        \"gender\": row.get(\"genderLabel\", {}).get(\"value\", \"Unknown\")  # Valor por defecto si no hay g√©nero\n",
    "                    })\n",
    "                batch_success = True\n",
    "                i += batch_size\n",
    "                pbar.update(batch_size)\n",
    "                time.sleep(0.8)\n",
    "            else:\n",
    "                batch_size = batch_size // 2\n",
    "\n",
    "        if not batch_success:\n",
    "            print(f\"‚ö†Ô∏è  Saltando artista en √≠ndice {i}: {artistas_unicos[i]}\")\n",
    "            i += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "# =======================\n",
    "# 4. GUARDAR RESULTADOS\n",
    "# =======================\n",
    "columnas_ordenadas = [\"artist\", \"country\", \"award\", \"death\", \"gender\"]\n",
    "df_result = pd.DataFrame(results, columns=columnas_ordenadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c37231c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo 'wikidata_artists_part1.csv' creado correctamente.\n",
      "‚úÖ Archivo 'wikidata_artists_part2.csv' creado correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Calcular el punto de divisi√≥n (por la mitad en este caso)\n",
    "halfway = len(df_result) // 2\n",
    "\n",
    "# Guardar la primera parte del DataFrame\n",
    "df_result.iloc[:halfway].to_csv(\"../data/wikidata_artists_part1.csv\", index=False)\n",
    "print(\"‚úÖ Archivo 'wikidata_artists_part1.csv' creado correctamente.\")\n",
    "\n",
    "# Guardar la segunda parte del DataFrame\n",
    "df_result.iloc[halfway:].to_csv(\"../data/wikidata_artists_part2.csv\", index=False)\n",
    "print(\"‚úÖ Archivo 'wikidata_artists_part2.csv' creado correctamente.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
